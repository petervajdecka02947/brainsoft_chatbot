{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e9370097-a055-41ca-bc61-71e1b1f44560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install pinecone-client\n",
    "#!pip install openai\n",
    "#!pip install matplotlib\n",
    "#%pip install --upgrade tiktoken\n",
    "#%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ee64cc99-8f10-41b9-867c-ae18a7c91d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your environment variables as a dictionary\n",
    "# env_variables = {\n",
    "#     'OPENAI_API_KEY': OPENAI_API_KEY,\n",
    "#     'PINECONE_API_KEY': PINECONE_API_KEY,\n",
    "#     'PINECONE_ENV': PINECONE_ENV,\n",
    "#     # Add more variables as needed\n",
    "# }\n",
    "\n",
    "# # Write the environment variables to .env file\n",
    "# with open('.env', 'w') as f:\n",
    "#     for key, value in env_variables.items():\n",
    "#         f.write(f'{key}={value}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8afa5-c374-4a3b-9519-29ad36e0afdd",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1fffafcb-0a99-4333-95b6-c69c14b03e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#from langchain.llms import OpenAI\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "#from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "3344f6d0-f614-4334-a11c-3942bc4cb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY= \"\"\n",
    "PINECONE_API_KEY=\"\"\n",
    "PINECONE_ENV= \"gcp-starter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d6078a-92fa-4307-a5ea-d285863346f6",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d05663b4-fc7c-4ac3-ba4e-bbaabd1d2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(text):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tokenizer\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens \n",
    "\n",
    "def calculate_statistics(data):\n",
    "    # Calculate basic statistics\n",
    "    try:\n",
    "        mode_value = statistics.mode(data)\n",
    "    except statistics.StatisticsError:\n",
    "        mode_value = None  # In case there's no unique mode\n",
    "\n",
    "    return {\n",
    "        'mean': statistics.mean(data),\n",
    "        'median': statistics.median(data),\n",
    "        'mode': mode_value,\n",
    "        'variance': statistics.variance(data),\n",
    "        'standard_deviation': statistics.stdev(data),\n",
    "        'min': min(data),\n",
    "        'max': max(data)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f550e7c6-f28b-4492-b0e4-991f6f5da0e6",
   "metadata": {},
   "source": [
    "# Load documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "73023d76-84f2-4403-9b3c-b1a0bd037930",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_links = pd.read_csv('./data/ibm_links.csv') .links.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cffd4e6d-ccd8-4633-9778-67f5214fdcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data is a list of Document objects loaded by WebBaseLoader\n",
    "loader = WebBaseLoader(data_links)\n",
    "data = loader.load()\n",
    "\n",
    "# This dictionary will map document content to the shortest source link and the document itself\n",
    "content_to_document_map = {}\n",
    "\n",
    "for doc in data:\n",
    "    doc_content = doc.page_content\n",
    "    doc_source = doc.metadata['source']\n",
    "    \n",
    "    # Check if the document content is already in the map\n",
    "    # and if the current source URL is shorter than the one stored\n",
    "    if (doc_content not in content_to_document_map or \n",
    "            len(doc_source) < len(content_to_document_map[doc_content]['source'])):\n",
    "        content_to_document_map[doc_content] = {\n",
    "            'source': doc_source,\n",
    "            'document': doc  # Storing the document object directly\n",
    "        }\n",
    "\n",
    "# Now that we have our unique documents, we can create two lists\n",
    "unique_sources = [details['source'] for details in content_to_document_map.values()]\n",
    "unique_documents = [details['document'] for details in content_to_document_map.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0f8527ee-4f96-4b90-a552-8642e4735525",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unique_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "25b4f5c3-bdce-417e-a348-d9f4778dddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "78f32721-868c-4762-82dd-c23c8d282d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ef77247f-3cf4-40ee-915d-6d253e03fb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"\\n\\n\\n\\n\\n\\n\\nMetadata - IBM Generative AI Python SDK (Tech Preview)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\n\\n\\n\\n\\n\\nMenu\\n\\n\\n\\n\\n\\n\\n\\nExpand\\n\\n\\n\\n\\n\\nLight mode\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDark mode\\n\\n\\n\\n\\n\\n\\nAuto light/dark mode\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHide navigation sidebar\\n\\n\\nHide table of contents sidebar\\n\\n\\n\\n\\n\\nToggle site navigation sidebar\\n\\n\\n\\n\\nIBM Generative AI Python SDK (Tech Preview)\\n\\n\\n\\n\\nToggle Light / Dark / Auto color theme\\n\\n\\n\\n\\n\\n\\nToggle table of contents sidebar\\n\\n\\n\\n\\n\\n\\n\\nIBM Generative AI Python SDK (Tech Preview)\\n\\n\\n\\n\\n\\n\\nAPIs:\\n\\nGENAIToggle navigation of GENAI\\nCredentials\\nMetadata\\nModel\\n\\n\\nServicesToggle navigation of Services\\nRequest Handler\\nService Interface\\n\\n\\nSchemasToggle navigation of Schemas\\nDescriptions\\nGenerate\\nHistory\\nResponses\\nToken\\nTunes\\nFiles\\n\\n\\nPromptsToggle navigation of Prompts\\nQuick Start\\nBasic Concepts\\nAnnexe\\nPrompts Pattern\\n\\n\\nExceptionsToggle navigation of Exceptions\\nGENAI Exceptions\\n\\n\\nRunning Custom Models\\n\\nExamples:\\n\\nSimple ExamplesToggle navigation of Simple Examples\\nAlice Bob QA\\nAlice Bob Talk\\nComplete My Code\\nCountry Capital QA\\nExplain my Code\\nGenerate with moderation\\nGrid search params\\nHistory\\nMany Greetings\\nModel utils\\nSelf reflection\\nStreaming\\nTokenize\\n\\n\\nAsync ExamplesToggle navigation of Async Examples\\nAsync Callback\\nAsync Greetings\\nAsync ordered responses\\nAsync tokenize\\n\\n\\nPromptsToggle navigation of Prompts\\nFrom all rows in a CSV\\nFrom a random row in a CSV\\nFrom a JSON\\nFrom a dataframe\\nInferring variables from CSV header\\n\\n\\nExtensionsToggle navigation of Extensions\\nHuggingFace agent\\nHuggingFace datasets\\nLangChain chains\\nLangChain generate\\nPandas\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBack to top\\n\\n\\n\\n\\nToggle Light / Dark / Auto color theme\\n\\n\\n\\n\\n\\n\\nToggle table of contents sidebar\\n\\n\\n\\n\\n\\nMetadata#\\n\\n\\nclass genai.metadata.Metadata(credentials: Credentials)#\\nBases: object\\n\\n\\nDEFAULT_MAX_PROMPTS = 5#\\n\\n\\n\\naccept_terms_of_use() → TermsOfUse#\\nAccepts the terms of use on GENAI.\\n\\nReturns:\\nTerms of Use Data\\n\\nReturn type:\\nTermsOfUse\\n\\n\\n\\n\\n\\nget_history(params: HistoryParams = HistoryParams(limit=None, offset=None, status=None, origin=None)) → HistoryResponse#\\n\\nThe requests endpoint provides the ability to retrieve past generation requestsand responses returned by the given models.\\nItems are returned in reverse chronological order.\\n\\n\\n\\nParameters:\\nparams (HistoryParams) – History parameters\\n\\nReturns:\\nThe History of requests and responses\\n\\nReturn type:\\nHistoryResponse\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNext\\n\\nModel\\n\\n\\n\\n\\n\\n\\n\\nPrevious\\n\\nCredentials\\n\\n\\n\\n\\n\\n\\n                Copyright © 2023, IBM Research\\n            \\n            Made with Sphinx and @pradyunsg's\\n            \\n            Furo\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            On this page\\n          \\n\\n\\n\\n\\nMetadata\\nMetadata\\nMetadata.DEFAULT_MAX_PROMPTS\\nMetadata.accept_terms_of_use()\\nMetadata.get_history()\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://ibm.github.io/ibm-generative-ai/rst_source/genai.metadata.html', 'title': 'Metadata - IBM Generative AI Python SDK (Tech Preview)', 'language': 'en'})"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be3e62-ef19-420b-96c8-299f145c66c9",
   "metadata": {},
   "source": [
    "# Check histogram of token_lengths (to check that we can make embeddings out of input texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "21007980-93e1-4d26-aceb-6f82e0d3bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "tokenizer  = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cc901e31-7f1b-420d-a1ff-2049399384d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = list(data[0])[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "92ce4535-69fd-4d44-b4c0-d5a0dfd1b578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_string(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "bf576cee-3c51-4ec8-9715-e9d3d954054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate token count: 381\n"
     ]
    }
   ],
   "source": [
    "links_length = []\n",
    "\n",
    "# Example usage:\n",
    "input_text = \"Calculate the OpenAI input length in tokens.\"\n",
    "print(\"Approximate token count:\", openai_approx_token_count(txt))\n",
    "for i in data:\n",
    "    len_txt = num_tokens_from_string(list(i)[0][1])\n",
    "    links_length.append(len_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "66630a40-ae26-40c5-b224-50098705580a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHHCAYAAABKudlQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/r0lEQVR4nO3de3zO9f/H8edlswN2wDDL5nyenKnIIctIcqhIaKSzQg7Vfn0lkaHyVYh8v4VKlAqdnGISieZMa84mh1jYjMxs798ffrt+LtvYZtt1fXjcb7fPjc/7874+79fnfV2bp8/1+VyXzRhjBAAAYFFFnF0AAADAjSDMAAAASyPMAAAASyPMAAAASyPMAAAASyPMAAAASyPMAAAASyPMAAAASyPMAAAASyPM4KZWqVIl9evXz9ll3PTeeustValSRW5ubmrQoIGzy4HF9evXTyVKlHB2GbAQwgwsY/bs2bLZbIqJiclye5s2bRQaGnrD4/zwww96/fXXb3g/t4rly5frpZdeUosWLTRr1iyNGzcu2779+vWTzWazLyVKlFCVKlX00EMP6auvvlJ6enohVm4t58+f1+uvv67Vq1fnqP/q1atls9n05ZdfFmxheZTb4wGuxd3ZBQAFKS4uTkWK5C6z//DDD5o2bRqBJodWrVqlIkWK6MMPP5SHh8d1+3t6euq///2vJOmff/7RoUOH9O233+qhhx5SmzZttHjxYvn6+hZ02ZZz/vx5jR49WtLl4G51N9vxwLkIM7ipeXp6OruEXDt37pyKFy/u7DJy7MSJE/L29s5RkJEkd3d39enTx6Ft7NixGj9+vCIjI/Xkk0/q888/L4hSAdykeJsJN7Wrr5lJTU3V6NGjVb16dXl5eal06dJq2bKlVqxYIeny2yDTpk2TJIe3QzKcO3dOw4YNU3BwsDw9PVWzZk29/fbbuvrL5//55x8NGjRIAQEB8vHx0QMPPKAjR47IZrM5nPF5/fXXZbPZ9Pvvv+vRRx9VyZIl1bJlS0nS9u3b1a9fP1WpUkVeXl4KDAzU448/rr///tthrIx97N69W3369JGfn5/KlCmjkSNHyhijw4cPq0uXLvL19VVgYKDeeeedHM3dpUuXNGbMGFWtWlWenp6qVKmS/ud//kcpKSn2PjabTbNmzdK5c+fsczV79uwc7f9qr7zyitq3b68FCxZo9+7dDtvef/991a1bV56engoKCtLAgQN15syZTPvYsGGD7rvvPpUsWVLFixfX7bffrnfffde+vU2bNlmeBejXr58qVapkXz948KBsNpvefvttTZs2TVWqVFGxYsXUvn17HT58WMYYjRkzRhUqVJC3t7e6dOmiU6dOZdrvkiVLdPfdd6t48eLy8fFRp06dtGvXrkxjlyhRQkeOHFHXrl1VokQJlSlTRsOHD1daWpq9njJlykiSRo8ebZ/r/Dh7eObMGQ0ZMsT+mq5WrZomTJjg8JbflfMxc+ZM+2uiadOm+u233zLtc8GCBapTp468vLwUGhqqhQsXOsxxTo/nWnOSYf78+WrcuLF8fHzk6+urevXqOTznuDVwZgaWk5iYqISEhEztqamp133s66+/rqioKD3xxBNq1qyZkpKSFBMTo82bN+vee+/V008/raNHj2rFihX65JNPHB5rjNEDDzyg6OhoDRgwQA0aNNCyZcs0YsQIHTlyRP/+97/tffv166cvvvhCffv21R133KGffvpJnTp1yrauhx9+WNWrV9e4cePswWjFihXav3+/+vfvr8DAQO3atUszZ87Url279OuvvzqELEnq2bOnateurfHjx+v777/X2LFjVapUKX3wwQe65557NGHCBM2dO1fDhw9X06ZN1apVq2vO1RNPPKE5c+booYce0rBhw7RhwwZFRUUpNjZWCxculCR98sknmjlzpjZu3Gh/6+iuu+667vOQnb59+2r58uVasWKFatSoIenyczZ69GiFhYXp2WefVVxcnKZPn67ffvtN69atU9GiRe3zdf/996t8+fIaPHiwAgMDFRsbq++++06DBw/OUz1z587VxYsX9cILL+jUqVOaOHGievTooXvuuUerV6/Wyy+/rL1792rKlCkaPny4PvroI/tjP/nkE0VERCg8PFwTJkzQ+fPnNX36dLVs2VJbtmxxCE9paWkKDw9X8+bN9fbbb+vHH3/UO++8o6pVq+rZZ59VmTJlNH36dD377LPq1q2bunfvLkm6/fbb8zjTl50/f16tW7fWkSNH9PTTTyskJES//PKLIiMjdezYMU2ePNmh/2effaazZ8/q6aefls1m08SJE9W9e3ft37/f/jx8//336tmzp+rVq6eoqCidPn1aAwYM0G233WbfT06O53pzIl1+znv16qV27dppwoQJkqTY2FitW7cuz885LMoAFjFr1iwj6ZpL3bp1HR5TsWJFExERYV+vX7++6dSp0zXHGThwoMnqR2PRokVGkhk7dqxD+0MPPWRsNpvZu3evMcaYTZs2GUlmyJAhDv369etnJJlRo0bZ20aNGmUkmV69emUa7/z585na5s2bZySZNWvWZNrHU089ZW+7dOmSqVChgrHZbGb8+PH29tOnTxtvb2+HOcnK1q1bjSTzxBNPOLQPHz7cSDKrVq2yt0VERJjixYtfc3857btlyxYjybz44ovGGGNOnDhhPDw8TPv27U1aWpq939SpU40k89FHH9mPt3LlyqZixYrm9OnTDvtMT0+3/71169amdevWWdZVsWJF+/qBAweMJFOmTBlz5swZe3tkZKSRZOrXr29SU1Pt7b169TIeHh7mwoULxhhjzp49a/z9/c2TTz7pMM7x48eNn5+fQ3tERISRZN544w2Hvg0bNjSNGze2r588eTLT6+daoqOjjSSzYMGCbPuMGTPGFC9e3Ozevduh/ZVXXjFubm4mPj7eYT5Kly5tTp06Ze+3ePFiI8l8++239rZ69eqZChUqmLNnz9rbVq9ebSQ5zPG1jienczJ48GDj6+trLl26dO3JwE2Pt5lgOdOmTdOKFSsyLTn5X6q/v7927dqlPXv25HrcH374QW5ubho0aJBD+7Bhw2SM0ZIlSyRJS5culSQ999xzDv1eeOGFbPf9zDPPZGrz9va2//3ChQtKSEjQHXfcIUnavHlzpv5PPPGE/e9ubm5q0qSJjDEaMGCAvd3f3181a9bU/v37s61FunyskjR06FCH9mHDhkm6/L/vgpBxO+7Zs2clST/++KMuXryoIUOGOFzI/eSTT8rX19dex5YtW3TgwAENGTJE/v7+Dvu8+gxWbjz88MPy8/Ozrzdv3lyS1KdPH7m7uzu0X7x4UUeOHJF0+YzBmTNn1KtXLyUkJNgXNzc3NW/eXNHR0ZnGuvo1cPfdd1/3ebpRCxYs0N13362SJUs61BkWFqa0tDStWbPGoX/Pnj1VsmRJhxol2es8evSoduzYoccee8zh1urWrVurXr16ua7venPi7++vc+fO2d8mxq2Lt5lgOc2aNVOTJk0ytWf8Qr6WN954Q126dFGNGjUUGhqqDh06qG/fvjkKQocOHVJQUJB8fHwc2mvXrm3fnvFnkSJFVLlyZYd+1apVy3bfV/eVpFOnTmn06NGaP3++Tpw44bAtMTExU/+QkBCHdT8/P3l5eSkgICBT+9XX3Vwt4xiurjkwMFD+/v72Y81vycnJkmSf44xxatas6dDPw8NDVapUsW/ft2+fJOXLrflXympOJSk4ODjL9tOnT0uSPSzfc889We736ru1vLy87NeQZChZsqR9fwVlz5492r59e6axM1z9urt6PjKCTUadGc9HVq/1atWqZRnCs5OTOXnuuef0xRdfqGPHjrrtttvUvn179ejRQx06dMjxOLg5EGZwS2nVqpX27dunxYsXa/ny5frvf/+rf//735oxY4bDmY3CduVZmAw9evTQL7/8ohEjRqhBgwYqUaKE0tPT1aFDhyw/j8XNzS1HbZIyXbCcnRs5q5EXO3fulHTt4HcjbDZblsd+9UWlGbKbv+vNa8bz88knnygwMDBTvyvP6lxrfwUtPT1d9957r1566aUst2dct5ThRl9PuZGTOSlbtqy2bt2qZcuWacmSJVqyZIlmzZqlxx57THPmzMn3muC6CDO45ZQqVUr9+/dX//79lZycrFatWun111+3h5ns/gGvWLGifvzxR509e9bh7Mwff/xh357xZ3p6ug4cOKDq1avb++3duzfHNZ4+fVorV67U6NGj9dprr9nb8/L2WF5kHMOePXvsZ54k6a+//tKZM2fsx5rfPvnkE9lsNt177732OqTLnxdUpUoVe7+LFy/qwIEDCgsLkyRVrVpV0uUwlNGWlZIlS2b51k1+n2nKqKds2bLXrCc3CiJYVq1aVcnJyflWY8bzldVr/eq2/DoeDw8Pde7cWZ07d1Z6erqee+45ffDBBxo5cmSBhWK4Hq6ZwS3l6rdXSpQooWrVqjncbpzxGS9X3/p73333KS0tTVOnTnVo//e//y2bzaaOHTtKksLDwyVdvp34SlOmTMlxnRn/K736f7xX311SUO67774sx5s0aZIkXfPOrLwaP368li9frp49e9pDYFhYmDw8PPTee+85zMWHH36oxMREex2NGjVS5cqVNXny5EzP25WPq1q1qv744w+dPHnS3rZt2zatW7cuX48lPDxcvr6+GjduXJZ32V05fk4VK1ZMUubX5Y3o0aOH1q9fr2XLlmXadubMGV26dClX+wsKClJoaKg+/vhj+1uGkvTTTz9px44dDn3z43iu/nkuUqSI/S3jK3+mcfPjzAxuKXXq1FGbNm3UuHFjlSpVSjExMfryyy/1/PPP2/s0btxYkjRo0CCFh4fLzc1NjzzyiDp37qy2bdvq1Vdf1cGDB1W/fn0tX75cixcv1pAhQ+z/G2/cuLEefPBBTZ48WX///bf91uyMz07Jyf9IfX191apVK02cOFGpqam67bbbtHz5ch04cKAAZiWz+vXrKyIiQjNnztSZM2fUunVrbdy4UXPmzFHXrl3Vtm3bPO/70qVL+vTTTyVdvrD50KFD+uabb7R9+3a1bdtWM2fOtPctU6aMIiMjNXr0aHXo0EEPPPCA4uLi9P7776tp06b2D98rUqSIpk+frs6dO6tBgwbq37+/ypcvrz/++EO7du2y/2P9+OOPa9KkSQoPD9eAAQN04sQJzZgxQ3Xr1lVSUtINzJgjX19fTZ8+XX379lWjRo30yCOPqEyZMoqPj9f333+vFi1aZArF1+Pt7a06dero888/V40aNVSqVCmFhoZe9zqhr776yn728EoREREaMWKEvvnmG91///3q16+fGjdurHPnzmnHjh368ssvdfDgwUzXXF3PuHHj1KVLF7Vo0UL9+/fX6dOnNXXqVIWGhjoEnLwez5WeeOIJnTp1Svfcc48qVKigQ4cOacqUKWrQoIHDGUXcApx2HxWQSxm3Zv/2229Zbm/duvV1b80eO3asadasmfH39zfe3t6mVq1a5s033zQXL16097l06ZJ54YUXTJkyZYzNZnO4Tfvs2bPmxRdfNEFBQaZo0aKmevXq5q233nK4/dcYY86dO2cGDhxoSpUqZUqUKGG6du1q4uLijCSHW6Uzbqs+efJkpuP5888/Tbdu3Yy/v7/x8/MzDz/8sDl69Gi2t3dfvY/sboPOap6ykpqaakaPHm0qV65sihYtaoKDg01kZKT99uPrjZOVjFtuM5ZixYqZSpUqmQcffNB8+eWXDrdfX2nq1KmmVq1apmjRoqZcuXLm2WefzXQLtjHGrF271tx7773Gx8fHFC9e3Nx+++1mypQpDn0+/fRTU6VKFePh4WEaNGhgli1blu2t2W+99ZbDY7O73Tm712Z0dLQJDw83fn5+xsvLy1StWtX069fPxMTEOMxJVvOX8bxe6ZdffjGNGzc2Hh4e171NO6PW7Jaff/7ZGHP5NR0ZGWmqVatmPDw8TEBAgLnrrrvM22+/bf+5yG4+jDFZ1jF//nxTq1Yt4+npaUJDQ80333xjHnzwQVOrVq0cHU9O5+TLL7807du3N2XLljUeHh4mJCTEPP300+bYsWPZzgtuTjZjCuDKLQCZbN26VQ0bNtSnn36q3r17O7scoFA1aNBAZcqU4TZqFAiumQEKwD///JOpbfLkySpSpMh1P3kXsLLU1NRM19qsXr1a27Zt4wslUWC4ZgYoABMnTtSmTZvUtm1bubu7228bfeqppzJ9RglwMzly5IjCwsLUp08fBQUF6Y8//tCMGTMUGBiY5YdDAvmBt5mAArBixQqNHj1av//+u5KTkxUSEqK+ffvq1VdfzfQZI8DNJDExUU899ZTWrVunkydPqnjx4mrXrp3Gjx9vv0geyG+EGQAAYGlcMwMAACyNMAMAACztpn/zPj09XUePHpWPj0+hf88MAADIG2OMzp49q6CgIBUpcu1zLzd9mDl69Ch3jwAAYFGHDx9WhQoVrtnnpg8zGV8IePjwYfn6+jq5GgAAkBNJSUkKDg52+GLf7Nz0YSbjrSVfX1/CDAAAFpOTS0S4ABgAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFgaYQYAAFiau7MLsLr4+HglJCQU+DgBAQEKCQkp8HEAALAawswNiI+PV82atXXhwvkCH8vLq5ji4mIJNAAAXIUwcwMSEhL+L8h8Kql2AY4UqwsX+ighIYEwAwDAVQgz+aK2pEbOLgIAgFsSFwADAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLc2qYWbNmjTp37qygoCDZbDYtWrQoU5/Y2Fg98MAD8vPzU/HixdW0aVPFx8cXfrEAAMAlOTXMnDt3TvXr19e0adOy3L5v3z61bNlStWrV0urVq7V9+3aNHDlSXl5ehVwpAABwVe7OHLxjx47q2LFjtttfffVV3XfffZo4caK9rWrVqoVRGgAAsAiXvWYmPT1d33//vWrUqKHw8HCVLVtWzZs3z/KtqCulpKQoKSnJYQEAADcvlw0zJ06cUHJyssaPH68OHTpo+fLl6tatm7p3766ffvop28dFRUXJz8/PvgQHBxdi1QAAoLC5bJhJT0+XJHXp0kUvvviiGjRooFdeeUX333+/ZsyYke3jIiMjlZiYaF8OHz5cWCUDAAAncOo1M9cSEBAgd3d31alTx6G9du3aWrt2bbaP8/T0lKenZ0GXBwAAXITLnpnx8PBQ06ZNFRcX59C+e/duVaxY0UlVAQAAV+PUMzPJycnau3evff3AgQPaunWrSpUqpZCQEI0YMUI9e/ZUq1at1LZtWy1dulTffvutVq9e7byiAQCAS3FqmImJiVHbtm3t60OHDpUkRUREaPbs2erWrZtmzJihqKgoDRo0SDVr1tRXX32lli1bOqtkAADgYpwaZtq0aSNjzDX7PP7443r88ccLqSIAAGA1LnvNDAAAQE4QZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKURZgAAgKU5NcysWbNGnTt3VlBQkGw2mxYtWpRt32eeeUY2m02TJ08utPoAAIDrc2qYOXfunOrXr69p06Zds9/ChQv166+/KigoqJAqAwAAVuHuzME7duyojh07XrPPkSNH9MILL2jZsmXq1KlTIVUGAACswqlh5nrS09PVt29fjRgxQnXr1s3RY1JSUpSSkmJfT0pKKqjyAACAC3DpC4AnTJggd3d3DRo0KMePiYqKkp+fn30JDg4uwAoBAICzuWyY2bRpk959913Nnj1bNpstx4+LjIxUYmKifTl8+HABVgkAAJzNZcPMzz//rBMnTigkJETu7u5yd3fXoUOHNGzYMFWqVCnbx3l6esrX19dhAQAANy+XvWamb9++CgsLc2gLDw9X37591b9/fydVBQAAXI1Tw0xycrL27t1rXz9w4IC2bt2qUqVKKSQkRKVLl3boX7RoUQUGBqpmzZqFXSoAAHBRTg0zMTExatu2rX196NChkqSIiAjNnj3bSVUBAAArcWqYadOmjYwxOe5/8ODBgisGAABYksteAAwAAJAThBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBpTg0za9asUefOnRUUFCSbzaZFixbZt6Wmpurll19WvXr1VLx4cQUFBemxxx7T0aNHnVcwAABwOU4NM+fOnVP9+vU1bdq0TNvOnz+vzZs3a+TIkdq8ebO+/vprxcXF6YEHHnBCpQAAwFW5O3Pwjh07qmPHjllu8/Pz04oVKxzapk6dqmbNmik+Pl4hISGFUSIAAHBxTg0zuZWYmCibzSZ/f/9s+6SkpCglJcW+npSUVAiVAQAAZ7HMBcAXLlzQyy+/rF69esnX1zfbflFRUfLz87MvwcHBhVglAAAobJYIM6mpqerRo4eMMZo+ffo1+0ZGRioxMdG+HD58uJCqBAAAzuDybzNlBJlDhw5p1apV1zwrI0menp7y9PQspOoAAICzuXSYyQgye/bsUXR0tEqXLu3skgAAgItxaphJTk7W3r177esHDhzQ1q1bVapUKZUvX14PPfSQNm/erO+++05paWk6fvy4JKlUqVLy8PBwVtkAAMCFODXMxMTEqG3btvb1oUOHSpIiIiL0+uuv65tvvpEkNWjQwOFx0dHRatOmTWGVCQAAXJhTw0ybNm1kjMl2+7W2AQAASBa5mwkAACA7hBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBphBkAAGBpeQoz+/fvz+86AAAA8iRPYaZatWpq27atPv30U124cCG/awIAAMixPIWZzZs36/bbb9fQoUMVGBiop59+Whs3bszv2gAAAK4rT2GmQYMGevfdd3X06FF99NFHOnbsmFq2bKnQ0FBNmjRJJ0+ezO86AQAAsnRDFwC7u7ure/fuWrBggSZMmKC9e/dq+PDhCg4O1mOPPaZjx47lV50AAABZuqEwExMTo+eee07ly5fXpEmTNHz4cO3bt08rVqzQ0aNH1aVLl/yqEwAAIEt5CjOTJk1SvXr1dNddd+no0aP6+OOPdejQIY0dO1aVK1fW3XffrdmzZ2vz5s3X3M+aNWvUuXNnBQUFyWazadGiRQ7bjTF67bXXVL58eXl7eyssLEx79uzJS8kAAOAmlacwM336dD366KM6dOiQFi1apPvvv19FijjuqmzZsvrwww+vuZ9z586pfv36mjZtWpbbJ06cqPfee08zZszQhg0bVLx4cYWHh3MHFQAAsHPPy4NycnbEw8NDERER1+zTsWNHdezYMcttxhhNnjxZ//rXv+xvV3388ccqV66cFi1apEceeST3hQMAgJtOns7MzJo1SwsWLMjUvmDBAs2ZM+eGi5KkAwcO6Pjx4woLC7O3+fn5qXnz5lq/fn2+jAEAAKwvT2EmKipKAQEBmdrLli2rcePG3XBRknT8+HFJUrly5Rzay5UrZ9+WlZSUFCUlJTksAADg5pWnMBMfH6/KlStnaq9YsaLi4+NvuKgbERUVJT8/P/sSHBzs1HoAAEDBylOYKVu2rLZv356pfdu2bSpduvQNFyVJgYGBkqS//vrLof2vv/6yb8tKZGSkEhMT7cvhw4fzpR4AAOCa8hRmevXqpUGDBik6OlppaWlKS0vTqlWrNHjw4Hy7MLdy5coKDAzUypUr7W1JSUnasGGD7rzzzmwf5+npKV9fX4cFAADcvPJ0N9OYMWN08OBBtWvXTu7ul3eRnp6uxx57LFfXzCQnJ2vv3r329QMHDmjr1q0qVaqUQkJCNGTIEI0dO1bVq1dX5cqVNXLkSAUFBalr1655KRsAANyE8hRmPDw89Pnnn2vMmDHatm2bvL29Va9ePVWsWDFX+4mJiVHbtm3t60OHDpUkRUREaPbs2XrppZd07tw5PfXUUzpz5oxatmyppUuXysvLKy9lAwCAm5DNGGOcXURBSkpKkp+fnxITE/P9LafNmzercePGkjZJapSv+75qJEmNtWnTJjVqVJDjAADgGnLz73eezsykpaVp9uzZWrlypU6cOKH09HSH7atWrcrLbgEAAHItT2Fm8ODBmj17tjp16qTQ0FDZbLb8rgsAACBH8hRm5s+fry+++EL33XdfftcDAACQK3m6NdvDw0PVqlXL71oAAAByLU9hZtiwYXr33Xd1k187DAAALCBPbzOtXbtW0dHRWrJkierWrauiRYs6bP/666/zpTgAAIDryVOY8ff3V7du3fK7FgAAgFzLU5iZNWtWftcBAACQJ3m6ZkaSLl26pB9//FEffPCBzp49K0k6evSokpOT8604AACA68nTmZlDhw6pQ4cOio+PV0pKiu699175+PhowoQJSklJ0YwZM/K7TgAAgCzl6czM4MGD1aRJE50+fVre3t729m7dujl8yzUAAEBBy9OZmZ9//lm//PKLPDw8HNorVaqkI0eO5EthAAAAOZGnMzPp6elKS0vL1P7nn3/Kx8fnhosCAADIqTyFmfbt22vy5Mn2dZvNpuTkZI0aNYqvOAAAAIUqT28zvfPOOwoPD1edOnV04cIFPfroo9qzZ48CAgI0b968/K4RAAAgW3kKMxUqVNC2bds0f/58bd++XcnJyRowYIB69+7tcEEwAABAQctTmJEkd3d39enTJz9rAQAAyLU8hZmPP/74mtsfe+yxPBUDAACQW3kKM4MHD3ZYT01N1fnz5+Xh4aFixYoRZgAAQKHJ091Mp0+fdliSk5MVFxenli1bcgEwAAAoVHn+bqarVa9eXePHj8901gYAAKAg5VuYkS5fFHz06NH83CUAAMA15emamW+++cZh3RijY8eOaerUqWrRokW+FAYAAJATeQozXbt2dVi32WwqU6aM7rnnHr3zzjv5URcAAECO5CnMpKen53cdAAAAeZKv18wAAAAUtjydmRk6dGiO+06aNCkvQwAAAORInsLMli1btGXLFqWmpqpmzZqSpN27d8vNzU2NGjWy97PZbPlTJQAAQDbyFGY6d+4sHx8fzZkzRyVLlpR0+YP0+vfvr7vvvlvDhg3L1yIBAACyk6drZt555x1FRUXZg4wklSxZUmPHjuVuJgAAUKjyFGaSkpJ08uTJTO0nT57U2bNnb7goAACAnMpTmOnWrZv69++vr7/+Wn/++af+/PNPffXVVxowYIC6d++eb8WlpaVp5MiRqly5sry9vVW1alWNGTNGxph8GwMAAFhbnq6ZmTFjhoYPH65HH31Uqampl3fk7q4BAwborbfeyrfiJkyYoOnTp2vOnDmqW7euYmJi1L9/f/n5+WnQoEH5Ng4AALCuPIWZYsWK6f3339dbb72lffv2SZKqVq2q4sWL52txv/zyi7p06aJOnTpJkipVqqR58+Zp48aN+ToOAACwrjyFmQzHjh3TsWPH1KpVK3l7e8sYk6+3Y991112aOXOmdu/erRo1amjbtm1au3btNT+7JiUlRSkpKfb1pKSkfKsH+Ss+Pl4JCQmFMlZAQIBCQkIKZSwAQOHKU5j5+++/1aNHD0VHR8tms2nPnj2qUqWKBgwYoJIlS+bbHU2vvPKKkpKSVKtWLbm5uSktLU1vvvmmevfune1joqKiNHr06HwZHwUnPj5eNWvW1oUL5wtlPC+vYoqLiyXQAMBNKE9h5sUXX1TRokUVHx+v2rVr29t79uypoUOH5luY+eKLLzR37lx99tlnqlu3rrZu3aohQ4YoKChIERERWT4mMjLS4ROKk5KSFBwcnC/1IP8kJCT8X5D5VFLt63W/QbG6cKGPEhISCDMAcBPKU5hZvny5li1bpgoVKji0V69eXYcOHcqXwiRpxIgReuWVV/TII49IkurVq6dDhw4pKioq2zDj6ekpT0/PfKsBBa22pEbX7QUAQHbydGv2uXPnVKxYsUztp06dytcgcf78eRUp4liim5sb39oNAADs8hRm7r77bn388cf2dZvNpvT0dE2cOFFt27bNt+I6d+6sN998U99//70OHjyohQsXatKkSerWrVu+jQEAAKwtT28zTZw4Ue3atVNMTIwuXryol156Sbt27dKpU6e0bt26fCtuypQpGjlypJ577jmdOHFCQUFBevrpp/Xaa6/l2xgAAMDa8hRmQkNDtXv3bk2dOlU+Pj5KTk5W9+7dNXDgQJUvXz7fivPx8dHkyZM1efLkfNsnAAC4ueQ6zKSmpqpDhw6aMWOGXn311YKoCQAAIMdyfc1M0aJFtX379oKoBQAAINfydAFwnz599OGHH+Z3LQAAALmWp2tmLl26pI8++kg//vijGjdunOk7ma71dQMAAAD5KVdhZv/+/apUqZJ27typRo0uf9DZ7t27Hfrk53czAQAAXE+uwkz16tV17NgxRUdHS7r89QXvvfeeypUrVyDFAQAAXE+urpkxxjisL1myROfOncvXggAAAHIjTxcAZ7g63AAAABS2XIUZm82W6ZoYrpEBAADOlKtrZowx6tevn/3LJC9cuKBnnnkm091MX3/9df5VCAAAcA25CjMREREO63369MnXYgAAAHIrV2Fm1qxZBVUHAABAntzQBcAAAADORpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACWRpgBAACW5vJh5siRI+rTp49Kly4tb29v1atXTzExMc4uCwAAuAh3ZxdwLadPn1aLFi3Utm1bLVmyRGXKlNGePXtUsmRJZ5cGAABchEuHmQkTJig4OFizZs2yt1WuXNmJFQEAAFfj0m8zffPNN2rSpIkefvhhlS1bVg0bNtR//vOfaz4mJSVFSUlJDgsAALh5uXSY2b9/v6ZPn67q1atr2bJlevbZZzVo0CDNmTMn28dERUXJz8/PvgQHBxdixQAAoLC5dJhJT09Xo0aNNG7cODVs2FBPPfWUnnzySc2YMSPbx0RGRioxMdG+HD58uBArBgAAhc2lw0z58uVVp04dh7batWsrPj4+28d4enrK19fXYQEAADcvlw4zLVq0UFxcnEPb7t27VbFiRSdVBAAAXI1Lh5kXX3xRv/76q8aNG6e9e/fqs88+08yZMzVw4EBnlwYAAFyES4eZpk2bauHChZo3b55CQ0M1ZswYTZ48Wb1793Z2aQAAwEW49OfMSNL999+v+++/39llAAAAF+XSZ2YAAACuhzADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAsjTADAAAszVJhZvz48bLZbBoyZIizSwEAAC7CMmHmt99+0wcffKDbb7/d2aUAAAAXYokwk5ycrN69e+s///mPSpYs6exyAACAC3F3dgE5MXDgQHXq1ElhYWEaO3bsNfumpKQoJSXFvp6UlFTQ5RWa2NjYQhknICBAISEhhTIWAAA3yuXDzPz587V582b99ttvOeofFRWl0aNHF3BVhe2YpCLq06dPoYzm5VVMcXGxBBoAgCW4dJg5fPiwBg8erBUrVsjLyytHj4mMjNTQoUPt60lJSQoODi6oEgvJGUnpkj6VVLuAx4rVhQt9lJCQQJgBAFiCS4eZTZs26cSJE2rUqJG9LS0tTWvWrNHUqVOVkpIiNzc3h8d4enrK09OzsEstJLUlNbpuLwAAbiUuHWbatWunHTt2OLT1799ftWrV0ssvv5wpyAAAgFuPS4cZHx8fhYaGOrQVL15cpUuXztQOAABuTZa4NRsAACA7Ln1mJiurV692dgkAAMCFcGYGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYGmEGAABYmuW+NRvIq9jY2AIfIyAgQCEhIQU+DgDg/xFmcAs4JqmI+vTpU+AjeXkVU1xcLIEGAAoRYQa3gDOS0iV9Kql2AY4TqwsX+ighIYEwAwCFiDCDW0htSY2cXQQAIJ9xATAAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0wgwAALA0lw8zUVFRatq0qXx8fFS2bFl17dpVcXFxzi4LAAC4CJcPMz/99JMGDhyoX3/9VStWrFBqaqrat2+vc+fOObs0AADgAtydXcD1LF261GF99uzZKlu2rDZt2qRWrVo5qSoAAOAqXD7MXC0xMVGSVKpUqSy3p6SkKCUlxb6elJRUKHXdbGJjYy29fwDArcNSYSY9PV1DhgxRixYtFBoammWfqKgojR49upAru5kck1REffr0cXYhAADkiKXCzMCBA7Vz506tXbs22z6RkZEaOnSofT0pKUnBwcGFUd5N4oykdEmfSqpdgOP8IGlkAe4fAHCrsEyYef755/Xdd99pzZo1qlChQrb9PD095enpWYiV3axqS2pUgPvnbSYAQP5w+TBjjNELL7yghQsXavXq1apcubKzSwIAAC7E5cPMwIED9dlnn2nx4sXy8fHR8ePHJUl+fn7y9vZ2cnUAAMDZXP5zZqZPn67ExES1adNG5cuXty+ff/65s0sDAAAuwOXPzBhjnF0CAABwYS5/ZgYAAOBaCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSCDMAAMDSXP5bswGriY2NLZRxUlJS5OnpedOMI0kBAQEKCQkplLFuNvHx8UpISCiUsXierKGwXhOu8HogzAD55pikIurTp08hjecmKe0mGkfy8iqmuLhYp/9itJr4+HjVrFlbFy6cL5TxeJ5cX2G+Jlzh9UCYAfLNGUnpkj6VVLuAx/pB0shCGKuwxpGkWF240EcJCQn8I5lLCQkJ//ePFs8TLiu814RrvB4IM0C+qy2pUQGPkfFWVkGPVVjjIH/wPOFqt8ZrgguAAQCApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApRFmAACApVkizEybNk2VKlWSl5eXmjdvro0bNzq7JAAA4CJcPsx8/vnnGjp0qEaNGqXNmzerfv36Cg8P14kTJ5xdGgAAcAEuH2YmTZqkJ598Uv3791edOnU0Y8YMFStWTB999JGzSwMAAC7ApcPMxYsXtWnTJoWFhdnbihQporCwMK1fv96JlQEAAFfh7uwCriUhIUFpaWkqV66cQ3u5cuX0xx9/ZPmYlJQUpaSk2NcTExMlSUlJSfleX3Jy8v/9bZOk5Gt1vUGxhTROYY7FMVljrMI8prjLI23adMXPVsEoUqSI0tPTC3SMwhwrLi7u//7G8+TqYxXWOIX3mrg8TnJycr7/O5uxP2PM9TsbF3bkyBEjyfzyyy8O7SNGjDDNmjXL8jGjRo0yklhYWFhYWFhuguXw4cPXzQsufWYmICBAbm5u+uuvvxza//rrLwUGBmb5mMjISA0dOtS+np6erlOnTql06dKy2WwFWm92kpKSFBwcrMOHD8vX19cpNdzMmN+CxxwXLOa3YDG/Ba8g5tgYo7NnzyooKOi6fV06zHh4eKhx48ZauXKlunbtKulyOFm5cqWef/75LB/j6ekpT09PhzZ/f/8CrjRnfH19+UEqQMxvwWOOCxbzW7CY34KX33Ps5+eXo34uHWYkaejQoYqIiFCTJk3UrFkzTZ48WefOnVP//v2dXRoAAHABLh9mevbsqZMnT+q1117T8ePH1aBBAy1dujTTRcEAAODW5PJhRpKef/75bN9WsgJPT0+NGjUq09tfyB/Mb8FjjgsW81uwmN+C5+w5thmTk3ueAAAAXJNLf2geAADA9RBmAACApRFmAACApRFmAACApRFmCti0adNUqVIleXl5qXnz5tq4caOzS3JJUVFRatq0qXx8fFS2bFl17dr1iu8WuezChQsaOHCgSpcurRIlSujBBx/M9OnQ8fHx6tSpk4oVK6ayZctqxIgRunTpkkOf1atXq1GjRvL09FS1atU0e/bsgj48lzN+/HjZbDYNGTLE3sb83rgjR46oT58+Kl26tLy9vVWvXj3FxMTYtxtj9Nprr6l8+fLy9vZWWFiY9uzZ47CPU6dOqXfv3vL19ZW/v78GDBiQ6TuQtm/frrvvvlteXl4KDg7WxIkTC+X4nCktLU0jR45U5cqV5e3trapVq2rMmDEO39vD/ObOmjVr1LlzZwUFBclms2nRokUO2wtzPhcsWKBatWrJy8tL9erV0w8//JC7g7mxb0/CtcyfP994eHiYjz76yOzatcs8+eSTxt/f3/z111/OLs3lhIeHm1mzZpmdO3earVu3mvvuu8+EhISY5ORke59nnnnGBAcHm5UrV5qYmBhzxx13mLvuusu+/dKlSyY0NNSEhYWZLVu2mB9++MEEBASYyMhIe5/9+/ebYsWKmaFDh5rff//dTJkyxbi5uZmlS5cW6vE608aNG02lSpXM7bffbgYPHmxvZ35vzKlTp0zFihVNv379zIYNG8z+/fvNsmXLzN69e+19xo8fb/z8/MyiRYvMtm3bzAMPPGAqV65s/vnnH3ufDh06mPr165tff/3V/Pzzz6ZatWqmV69e9u2JiYmmXLlypnfv3mbnzp1m3rx5xtvb23zwwQeFeryF7c033zSlS5c23333nTlw4IBZsGCBKVGihHn33XftfZjf3Pnhhx/Mq6++ar7++msjySxcuNBhe2HN57p164ybm5uZOHGi+f33382//vUvU7RoUbNjx44cHwthpgA1a9bMDBw40L6elpZmgoKCTFRUlBOrsoYTJ04YSeann34yxhhz5swZU7RoUbNgwQJ7n9jYWCPJrF+/3hhz+QezSJEi5vjx4/Y+06dPN76+viYlJcUYY8xLL71k6tat6zBWz549TXh4eEEfkks4e/asqV69ulmxYoVp3bq1Pcwwvzfu5ZdfNi1btsx2e3p6ugkMDDRvvfWWve3MmTPG09PTzJs3zxhjzO+//24kmd9++83eZ8mSJcZms5kjR44YY4x5//33TcmSJe1znjF2zZo18/uQXEqnTp3M448/7tDWvXt307t3b2MM83ujrg4zhTmfPXr0MJ06dXKop3nz5ubpp5/Ocf28zVRALl68qE2bNiksLMzeVqRIEYWFhWn9+vVOrMwaEhMTJUmlSpWSJG3atEmpqakO81mrVi2FhITY53P9+vWqV6+ew6dDh4eHKykpSbt27bL3uXIfGX1uledk4MCB6tSpU6Y5YH5v3DfffKMmTZro4YcfVtmyZdWwYUP95z//sW8/cOCAjh8/7jA/fn5+at68ucMc+/v7q0mTJvY+YWFhKlKkiDZs2GDv06pVK3l4eNj7hIeHKy4uTqdPny7ow3Sau+66SytXrtTu3bslSdu2bdPatWvVsWNHScxvfivM+cyP3xuEmQKSkJCgtLS0TF+7UK5cOR0/ftxJVVlDenq6hgwZohYtWig0NFSSdPz4cXl4eGT60tAr5/P48eNZznfGtmv1SUpK0j///FMQh+My5s+fr82bNysqKirTNub3xu3fv1/Tp09X9erVtWzZMj377LMaNGiQ5syZI+n/5+havxOOHz+usmXLOmx3d3dXqVKlcvU83IxeeeUVPfLII6pVq5aKFi2qhg0basiQIerdu7ck5je/FeZ8ZtcnN/Ntia8zwK1l4MCB2rlzp9auXevsUm4ahw8f1uDBg7VixQp5eXk5u5ybUnp6upo0aaJx48ZJkho2bKidO3dqxowZioiIcHJ11vfFF19o7ty5+uyzz1S3bl1t3bpVQ4YMUVBQEPMLzswUlICAALm5uWW6G+Svv/5SYGCgk6pyfc8//7y+++47RUdHq0KFCvb2wMBAXbx4UWfOnHHof+V8BgYGZjnfGduu1cfX11fe3t75fTguY9OmTTpx4oQaNWokd3d3ubu766efftJ7770nd3d3lStXjvm9QeXLl1edOnUc2mrXrq34+HhJ/z9H1/qdEBgYqBMnTjhsv3Tpkk6dOpWr5+FmNGLECPvZmXr16qlv37568cUX7Wcamd/8VZjzmV2f3Mw3YaaAeHh4qHHjxlq5cqW9LT09XStXrtSdd97pxMpckzFGzz//vBYuXKhVq1apcuXKDtsbN26sokWLOsxnXFyc4uPj7fN55513aseOHQ4/XCtWrJCvr6/9H5k777zTYR8ZfW7256Rdu3basWOHtm7dal+aNGmi3r172//O/N6YFi1aZPo4gd27d6tixYqSpMqVKyswMNBhfpKSkrRhwwaHOT5z5ow2bdpk77Nq1Sqlp6erefPm9j5r1qxRamqqvc+KFStUs2ZNlSxZssCOz9nOnz+vIkUc/8lyc3NTenq6JOY3vxXmfObL740cXyqMXJs/f77x9PQ0s2fPNr///rt56qmnjL+/v8PdILjs2WefNX5+fmb16tXm2LFj9uX8+fP2Ps8884wJCQkxq1atMjExMebOO+80d955p317xq3D7du3N1u3bjVLly41ZcqUyfLW4REjRpjY2Fgzbdq0W+bW4atdeTeTMczvjdq4caNxd3c3b775ptmzZ4+ZO3euKVasmPn000/tfcaPH2/8/f3N4sWLzfbt202XLl2yvNW1YcOGZsOGDWbt2rWmevXqDre6njlzxpQrV8707dvX7Ny508yfP98UK1bsprx1+EoRERHmtttus9+a/fXXX5uAgADz0ksv2fswv7lz9uxZs2XLFrNlyxYjyUyaNMls2bLFHDp0yBhTePO5bt064+7ubt5++20TGxtrRo0axa3ZrmbKlCkmJCTEeHh4mGbNmplff/3V2SW5JElZLrNmzbL3+eeff8xzzz1nSpYsaYoVK2a6detmjh075rCfgwcPmo4dOxpvb28TEBBghg0bZlJTUx36REdHmwYNGhgPDw9TpUoVhzFuJVeHGeb3xn377bcmNDTUeHp6mlq1apmZM2c6bE9PTzcjR4405cqVM56enqZdu3YmLi7Ooc/ff/9tevXqZUqUKGF8fX1N//79zdmzZx36bNu2zbRs2dJ4enqa2267zYwfP77Aj83ZkpKSzODBg01ISIjx8vIyVapUMa+++qrDLb/Mb+5ER0dn+Xs3IiLCGFO48/nFF1+YGjVqGA8PD1O3bl3z/fff5+pYbMZc8fGJAAAAFsM1MwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwAAwNIIMwBuSm3atNGQIUOcXQaAQkCYAZAr/fr1k81m0/jx4x3aFy1aJJvNlu/jZLdUqlQp38YCYG2EGQC55uXlpQkTJuj06dMFNsa7776rY8eO2RdJmjVrln39t99+K7CxAVgLYQZAroWFhSkwMFBRUVHX7PfVV1+pbt268vT0VKVKlfTOO+/keAw/Pz8FBgbaF0ny9/e3r//+++9q1qyZPD09Vb58eb3yyiu6dOlStvv7/vvv5efnp7lz50qSDh8+rB49esjf31+lSpVSly5ddPDgQXv/fv36qWvXrnr77bdVvnx5lS5dWgMHDnT49t/3339f1atXl5eXl8qVK6eHHnoox8cHIP8QZgDkmpubm8aNG6cpU6bozz//zLLPpk2b1KNHDz3yyCPasWOHXn/9dY0cOVKzZ8++4fGPHDmi++67T02bNtW2bds0ffp0ffjhhxo7dmyW/T/77DP16tVLc+fOVe/evZWamqrw8HD5+Pjo559/1rp161SiRAl16NBBFy9etD8uOjpa+/btU3R0tObMmaPZs2fb64+JidGgQYP0xhtvKC4uTkuXLlWrVq1u+NgA5EGuvpYSwC0vIiLCdOnSxRhjzB133GEef/xxY4wxCxcuNFf+Snn00UfNvffe6/DYESNGmDp16uRpXElm4cKFxhhj/ud//sfUrFnTpKen27dPmzbNlChRwqSlpRlj/v9bwadOnWr8/PzM6tWr7X0/+eSTTI9PSUkx3t7eZtmyZfbjrFixorl06ZK9z8MPP2x69uxpjDHmq6++Mr6+viYpKSlPxwMg/3BmBkCeTZgwQXPmzFFsbGymbbGxsWrRooVDW4sWLbRnzx6lpaXd0LixsbG68847HS44btGihZKTkx3OFH355Zd68cUXtWLFCrVu3drevm3bNu3du1c+Pj4qUaKESpQooVKlSunChQvat2+fvV/dunXl5uZmXy9fvrxOnDghSbr33ntVsWJFValSRX379tXcuXN1/vz5GzouAHlDmAGQZ61atVJ4eLgiIyOdXUqWGjZsqDJlyuijjz6SMcbenpycrMaNG2vr1q0Oy+7du/Xoo4/a+xUtWtRhfzabTenp6ZIkHx8fbd68WfPmzVP58uX12muvqX79+jpz5kyhHBuA/0eYAXBDxo8fr2+//Vbr1693aK9du7bWrVvn0LZu3TrVqFHD4WxHXtSuXVvr1693CCjr1q2Tj4+PKlSoYG+rWrWqoqOjtXjxYr3wwgv29kaNGmnPnj0qW7asqlWr5rD4+fnluA53d3eFhYVp4sSJ2r59uw4ePKhVq1bd0LEByD3CDIAbUq9ePfXu3VvvvfeeQ/uwYcO0cuVKjRkzRrt379acOXM0depUDR8+3N6nXbt2mjp1aq7HfO6553T48GG98MIL+uOPP7R48WKNGjVKQ4cOVZEijr/WatSooejoaH311Vf2D9Hr3bu3AgIC1KVLF/388886cOCAVq9erUGDBmV7QfPVvvvuO7333nvaunWrDh06pI8//ljp6emqWbNmro8HwI0hzAC4YW+88Yb97ZcMjRo10hdffKH58+crNDRUr732mt544w3169fP3mffvn1KSEjI9Xi33XabfvjhB23cuFH169fXM888owEDBuhf//pXlv1r1qypVatWad68eRo2bJiKFSumNWvWKCQkRN27d1ft2rU1YMAAXbhwQb6+vjmqwd/fX19//bXuuece1a5dWzNmzNC8efNUt27dXB8PgBtjM1eepwUAALAYzswAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABLI8wAAABL+1+JyjULngU1NQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate bin width\n",
    "bin_width = 600  # You can change this value to adjust the width of the bins\n",
    "\n",
    "# Create bins with the specified width\n",
    "bins = range(min(links_length), max(links_length) + bin_width, bin_width)\n",
    "\n",
    "# Create histogram\n",
    "plt.hist(links_length, bins=bins, align='left', color='blue', edgecolor='black')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Histogram of Document Lengths')\n",
    "plt.xlabel('No. Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8cda3737-5c3f-45a4-9f69-7d08c24002c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1764.2051282051282\n",
      "Median: 911\n",
      "Mode: 432\n",
      "Variance: 3939287.0620782725\n",
      "Standard_deviation: 1984.7637295351485\n",
      "Min: 68\n",
      "Max: 10154\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "stats = calculate_statistics(links_length)\n",
    "\n",
    "for stat, value in stats.items():\n",
    "    print(f\"{stat.capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ff0b4a7-3800-4b70-ab2b-1dfc6a235b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc39207-1ae3-4154-8811-a1ab3386b9b8",
   "metadata": {},
   "source": [
    "### Because I use code to be transfered into embeddings, I split on hithest threshold in terms of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c4417b87-551a-4561-be21-fe6c8b77267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 5000, # 8150 max\n",
    "    chunk_overlap  = 300,\n",
    "    length_function = num_tokens_from_string,\n",
    "    add_start_index = True,)\n",
    "\n",
    "texts = text_splitter.split_documents(data)\n",
    "#texts = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c0b8edbc-74ae-4166-8c65-c4730fe13fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(texts[0])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "0a32ce7a-3d30-4cb7-97cd-a3ae118b20b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "adf68f81-80d4-4c92-a5df-a4b7dff707e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Metadata - IBM Generative AI Python SDK (Tech Preview)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\n\\n\\n\\n\\n\\nMenu\\n\\n\\n\\n\\n\\n\\n\\nExpand\\n\\n\\n\\n\\n\\nLight mode\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDark mode\\n\\n\\n\\n\\n\\n\\nAuto light/dark mode\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHide navigation sidebar\\n\\n\\nHide table of contents sidebar\\n\\n\\n\\n\\n\\nToggle site navigation sidebar\\n\\n\\n\\n\\nIBM Generative AI Python SDK (Tech Preview)\\n\\n\\n\\n\\nToggle Light / Dark / Auto color theme\\n\\n\\n\\n\\n\\n\\nToggle table of contents sidebar\\n\\n\\n\\n\\n\\n\\n\\nIBM Generative AI Python SDK (Tech Preview)\\n\\n\\n\\n\\n\\n\\nAPIs:\\n\\nGENAIToggle navigation of GENAI\\nCredentials\\nMetadata\\nModel\\n\\n\\nServicesToggle navigation of Services\\nRequest Handler\\nService Interface\\n\\n\\nSchemasToggle navigation of Schemas\\nDescriptions\\nGenerate\\nHistory\\nResponses\\nToken\\nTunes\\nFiles\\n\\n\\nPromptsToggle navigation of Prompts\\nQuick Start\\nBasic Concepts\\nAnnexe\\nPrompts Pattern\\n\\n\\nExceptionsToggle navigation of Exceptions\\nGENAI Exceptions\\n\\n\\nRunning Custom Models\\n\\nExamples:\\n\\nSimple ExamplesToggle navigation of Simple Examples\\nAlice Bob QA\\nAlice Bob Talk\\nComplete My Code\\nCountry Capital QA\\nExplain my Code\\nGenerate with moderation\\nGrid search params\\nHistory\\nMany Greetings\\nModel utils\\nSelf reflection\\nStreaming\\nTokenize\\n\\n\\nAsync ExamplesToggle navigation of Async Examples\\nAsync Callback\\nAsync Greetings\\nAsync ordered responses\\nAsync tokenize\\n\\n\\nPromptsToggle navigation of Prompts\\nFrom all rows in a CSV\\nFrom a random row in a CSV\\nFrom a JSON\\nFrom a dataframe\\nInferring variables from CSV header\\n\\n\\nExtensionsToggle navigation of Extensions\\nHuggingFace agent\\nHuggingFace datasets\\nLangChain chains\\nLangChain generate\\nPandas\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBack to top\\n\\n\\n\\n\\nToggle Light / Dark / Auto color theme\\n\\n\\n\\n\\n\\n\\nToggle table of contents sidebar\\n\\n\\n\\n\\n\\nMetadata#\\n\\n\\nclass genai.metadata.Metadata(credentials: Credentials)#\\nBases: object\\n\\n\\nDEFAULT_MAX_PROMPTS = 5#\\n\\n\\n\\naccept_terms_of_use() → TermsOfUse#\\nAccepts the terms of use on GENAI.\\n\\nReturns:\\nTerms of Use Data\\n\\nReturn type:\\nTermsOfUse\\n\\n\\n\\n\\n\\nget_history(params: HistoryParams = HistoryParams(limit=None, offset=None, status=None, origin=None)) → HistoryResponse#\\n\\nThe requests endpoint provides the ability to retrieve past generation requestsand responses returned by the given models.\\nItems are returned in reverse chronological order.\\n\\n\\n\\nParameters:\\nparams (HistoryParams) – History parameters\\n\\nReturns:\\nThe History of requests and responses\\n\\nReturn type:\\nHistoryResponse\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNext\\n\\nModel\\n\\n\\n\\n\\n\\n\\n\\nPrevious\\n\\nCredentials\\n\\n\\n\\n\\n\\n\\n                Copyright © 2023, IBM Research\\n            \\n            Made with Sphinx and @pradyunsg's\\n            \\n            Furo\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            On this page\\n          \\n\\n\\n\\n\\nMetadata\\nMetadata\\nMetadata.DEFAULT_MAX_PROMPTS\\nMetadata.accept_terms_of_use()\\nMetadata.get_history()\", metadata={'source': 'https://ibm.github.io/ibm-generative-ai/rst_source/genai.metadata.html', 'title': 'Metadata - IBM Generative AI Python SDK (Tech Preview)', 'language': 'en', 'start_index': 7})"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bbcd0-9c2f-4bcb-944b-a303d646a4ab",
   "metadata": {},
   "source": [
    "# Prepare pinecone vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "a53163d1-fd0e-46dd-85d3-ef16c31356aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(\n",
    "            api_key= PINECONE_API_KEY, # set api_key = 'yourapikey'\n",
    "            environment= PINECONE_ENV\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "910975df-e1e0-4381-9039-b2cb08217789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brainsoft']"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d9159ec4-00ed-4c76-9a58-6b66f9593255",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_n = \"brainsoft\"\n",
    "if index_n not in pinecone.list_indexes():\n",
    "    pinecone.create_index(name=index_n, dimension=1536, metric='cosine')\n",
    "\n",
    "index_name = pinecone.Index(index_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e470f1f4-07a3-4569-94e8-65c7d2d3c31d",
   "metadata": {},
   "source": [
    "# Initialize OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1dc36ee0-f1cd-432c-a8ba-04ceabc85297",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = OpenAIEmbeddings(model = 'text-embedding-ada-002', # 8191 tokens\n",
    "                                    openai_api_key=OPENAI_API_KEY) # set openai_api_key = 'your_openai_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "81197911-ae59-4743-a6da-dea3e71ad799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, \n",
    "                 model_name='gpt-3.5-turbo-16k',\n",
    "                 #max_tokens = 10000,\n",
    "                 temperature=0) # gpt-3.5-turbo-16k 'gpt-3.5-turbo'\n",
    "llm.predict(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79708737-3c9d-4df9-acc5-df6dea4fcd29",
   "metadata": {},
   "source": [
    "# Create embeddings from texts and save it to vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "567b9c07-0f54-4aed-be27-6e17842fd013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code block took 2.0808331966400146 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "vectordb = Pinecone.from_documents(texts, embeddings_model, index_name=index_n)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The code block took {elapsed_time} seconds to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb2b98f-9ef7-413d-a131-de13495add7a",
   "metadata": {},
   "source": [
    "# Create chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "068b77c7-c2bd-4625-a0e1-675842675c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template message\n",
    "# Always say \"thanks for asking!\" at the end of the answer. \n",
    "# If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "# Answer with python script only!\n",
    "#Use three sentences maximum and keep the answer as concise as possible.\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.  \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2d9a2b35-620e-4ed7-8cc8-061a7c660ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={'k': 1})\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key='question', output_key='answer', return_messages= True)\n",
    "#memory = VectorStoreRetrieverMemory(retriever=retriever, input_key='question', output_key='answer', return_messages= True)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(llm, \n",
    "                                              retriever = retriever, \n",
    "                                              combine_docs_chain_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "                                              return_source_documents=True, \n",
    "                                              memory = memory) # chain chain verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0de3bcdf-c8dc-46f1-85d6-771afd46aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "056ada09-f605-4735-953a-0a751e510525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The example of Alice Bob QA in Python can be found in the code snippet labeled \"Alice Bob QA\" in the provided context.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = 'Show an examples of Alice Bob QA in python ?'\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history}) # \"chat_history\": chat_history\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a36b0e8c-1f5a-4b6b-9fb0-2e208380a94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "72d3f6d2-1718-4c42-b5c3-59712856f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a Python script for Alice Bob QA:\n",
      "\n",
      "```python\n",
      "import os\n",
      "import time\n",
      "\n",
      "from dotenv import load_dotenv\n",
      "\n",
      "from genai.credentials import Credentials\n",
      "from genai.model import Model\n",
      "from genai.schemas import GenerateParams\n",
      "\n",
      "# make sure you have a .env file under genai root with\n",
      "# GENAI_KEY=<your-genai-key>\n",
      "# GENAI_API=<genai-api-endpoint>\n",
      "load_dotenv()\n",
      "api_key = os.getenv(\"GENAI_KEY\", None)\n",
      "api_endpoint = os.getenv(\"GENAI_API\", None)\n",
      "\n",
      "print(\"\\n------------- Example (Model QA)-------------\\n\")\n",
      "\n",
      "max_cycles = 20\n",
      "\n",
      "bob_params = GenerateParams(\n",
      "    decoding_method=\"sample\",\n",
      "    max_new_tokens=25,\n",
      "    min_new_tokens=1,\n",
      "    stream=False,\n",
      "    temperature=1,\n",
      "    top_k=50,\n",
      "    top_p=1,\n",
      ")\n",
      "\n",
      "alice_params = GenerateParams(\n",
      "    decoding_method=\"sample\",\n",
      "    max_new_tokens=45,\n",
      "    min_new_tokens=1,\n",
      "    stream=False,\n",
      "    temperature=0.05,\n",
      "    top_k=50,\n",
      "    top_p=1,\n",
      ")\n",
      "\n",
      "creds = Credentials(api_key, api_endpoint)\n",
      "bob_model = Model(\"google/flan-ul2\", params=bob_params, credentials=creds)\n",
      "alice_model = Model(\"google/flan-t5-xxl\", params=alice_params, credentials=creds)\n",
      "\n",
      "alice_q = \"What is 1 + 1?\"\n",
      "print(f\"[Alice][Q] {alice_q}\")\n",
      "\n",
      "for x in range(max_cycles):\n",
      "    bob_response = bob_model.generate([alice_q])\n",
      "    bob_a = bob_response[0].generated_text\n",
      "    print(f\"[Bob][A] {bob_a}\")\n",
      "\n",
      "    bob_q = \"What is \" + bob_a + \" + \" + bob_a + \"?\"\n",
      "    print(f\"[Bob][Q] {bob_q}\")\n",
      "\n",
      "    alice_response = alice_model.generate([bob_q])\n",
      "    alice_a = alice_response[0].generated_text\n",
      "    print(f\"[Alice][A] {alice_a}\")\n",
      "\n",
      "    alice_q = \"What is \" + alice_a + \" + \" + alice_a + \"?\"\n",
      "    print(f\"[Alice][Q] {alice_q}\")\n",
      "    time.sleep(0.5)\n",
      "```\n",
      "\n",
      "This script uses the IBM Generative AI Python SDK to perform a question-answering conversation between Alice and Bob. Alice asks a question, Bob generates an answer, and then Alice generates a new question based on Bob's answer. This process repeats for a specified number of cycles.\n"
     ]
    }
   ],
   "source": [
    "#chat_history = [(query, result[\"answer\"])]\n",
    "query = \"ok, but I want you to write python script!\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "9d8f39db-736e-47eb-99b2-ba42e4ffe2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5th argument in GenerateParams is the \"min_new_tokens\" parameter. It is set to \"None\" in the last output because it is an optional argument and its default value is not specified in the provided context.\n"
     ]
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"From your last output, what does mean the 5th argument in GenerateParams and why is it set just like it is?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6df65e6d-707b-4bb1-84e8-f7232fe2ddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the 5th argument in GenerateParams is the \"temperature\" parameter. It is set to \"float | None\" which means it can accept a floating-point number or be set to None. The reason for this is to provide flexibility in specifying the temperature value for generating text. If a specific temperature value is desired, it can be set as a float. If no temperature value is specified, it can be set to None and the default value will be used.\n"
     ]
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"Isnt it temperature ?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "4e28cf93-a8ce-4b8f-bd5e-e3bbbda2a26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5th argument in GenerateParams is \"min_new_tokens\". It is set to None by default. This argument specifies the minimum number of tokens that should be generated before considering any stop sequences. If stop sequences are given, they are ignored until the minimum number of tokens specified by this argument is generated.\n"
     ]
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"Provide only first sentence from your last message!\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058cf1cd-43c7-4101-b406-74954617da4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8984b-75d0-4df1-95f3-4ed9d3477a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
